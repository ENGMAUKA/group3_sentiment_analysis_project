{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f769af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard packages\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "from textwrap import fill \n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "#classification models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "\n",
    "# classification metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# scalers\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer, label_binarize\n",
    "\n",
    "# dummies\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# NLP libraries\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "from nltk import pos_tag\n",
    "from wordcloud import WordCloud \n",
    "\n",
    "# imbalanced-learn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83d8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8914 entries, 0 to 9069\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text          8914 non-null   object\n",
      " 1   sentiment     8914 non-null   int64 \n",
      " 2   cleaned_text  8914 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 278.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "sentiment_data = pd.read_csv(\"../data/cleaned_sentiment_data.csv\", encoding=\"ISO-8859-1\")\n",
    "sentiment_data\n",
    "\n",
    "# drop the irrelevant label and check the remaining labels\n",
    "\n",
    "sentiment_data = sentiment_data.query('sentiment != \"irrelevant\"')\n",
    "\n",
    "#confirm removal of the label\n",
    "sentiment_data[\"sentiment\"].value_counts()\n",
    "\n",
    "# convert sentiment column to integer\n",
    "sentiment_data[\"sentiment\"] = sentiment_data[\"sentiment\"].astype(int)\n",
    "sentiment_data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04913a20",
   "metadata": {},
   "source": [
    "# **4. Modelling**\n",
    "## **4.1 Data Preprocessing**\n",
    "Select the feature variable (X) and target variable (y). \n",
    "Split data into train and test sets for model testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f38767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into X and y\n",
    "\n",
    "X = sentiment_data[\"cleaned_text\"]\n",
    "y = sentiment_data[\"sentiment\"] # target variable\n",
    "\n",
    "# data split into train and test \n",
    "X_train, X_test, y_train,  y_test = train_test_split(X,y, test_size=0.25, stratify=y, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9a07c",
   "metadata": {},
   "source": [
    "**Model Statistics**\n",
    "Accuracy and Recall will be the main metric used to track model performance. However, accuracy recall, auc and f1 score will also be computed to provide additional details about the model using sklearn's classification_report function()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d5f18b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96391e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
